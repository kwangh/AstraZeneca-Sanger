{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import rpy2.robjects as robjects\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SignatureTranslatedFunction - Python:0x000000000A9679C8 / R:0x000000000C9179B0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robjects.r('''\n",
    "getObs_ch1 <- function(ls) {\n",
    "  return(data.frame(CELL_LINE=as.character(ls$CELL_LINE),\n",
    "                    COMBINATION_ID=as.character(ls$COMBINATION_ID),\n",
    "                    OBSERVATION=ls$SYNERGY_SCORE))\n",
    "}\n",
    "\n",
    "# Get the drug combinations score of Subchallenge 1\n",
    "getDrugCombiScore_ch1 <- function(obs, pred, confidence=NA, topX=10) {\n",
    "  R <- c()\n",
    "  obs <- read.csv(obs,stringsAsFactors = F)\n",
    "  obs <- getObs_ch1(obs)\n",
    "  pred <- read.csv(pred,stringsAsFactors=F)\n",
    "  pred <- pred[match(paste(obs$CELL_LINE,obs$COMBINATION_ID),paste(pred$CELL_LINE,pred$COMBINATION_ID)),]\n",
    "\n",
    "  pred$COMBINATION_ID <- gsub(\" \", \"\", pred$COMBINATION_ID)\n",
    "  for (i in as.character(unique(obs$COMBINATION_ID))) {\n",
    "      R <- c(R, cor(obs[obs$COMBINATION_ID == i, 'OBSERVATION'], \n",
    "                    pred[pred$COMBINATION_ID == i, 'PREDICTION']))\n",
    "  }\n",
    "  #Make NA's in R = 0\n",
    "  R[is.na(R)] = 0\n",
    "  names(R) <- as.character(unique(obs$COMBINATION_ID))\n",
    "  \n",
    "  if (!file.exists(confidence))\n",
    "    return(round(c(mean=mean(R),\n",
    "             ste=sd(R),\n",
    "             n=sum(!is.na(R))),2))\n",
    "  \n",
    "  confidence <- read.csv(confidence,stringsAsFactors=F)\n",
    "  confidence <- confidence[match(unique(obs$COMBINATION_ID),confidence$COMBINATION_ID),]\n",
    "\n",
    "  nStep <- 1000\n",
    "  nVal <- round(topX * (length(R) / 100))\n",
    "  boot_R <- rep(0, nVal)\n",
    "  for (i in 1:nStep) {\n",
    "    idx <- order(confidence$CONFIDENCE, sample(length(R)), decreasing = T)[1:nVal]\n",
    "    boot_R <- boot_R + R[idx]\n",
    "  }\n",
    "  \n",
    "  return(round(c(mean=mean(boot_R/nStep),\n",
    "                 ste=sd(boot_R/nStep),\n",
    "                 n=sum(!is.na(boot_R/nStep))),2))\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Get the global score of Subchallenge 1\n",
    "# ------------------------------------------------------------------------------------\n",
    "getGlobalScore_ch1 <- function(obs, pred) {\n",
    "  obs <- read.csv(obs, stringsAsFactors=F)\n",
    "  obs <- getObs_ch1(obs)\n",
    "  pred <- read.csv(pred,stringsAsFactors=F)\n",
    "  pred <- pred[match(paste(obs$CELL_LINE,obs$COMBINATION_ID),paste(pred$CELL_LINE,pred$COMBINATION_ID)),]\n",
    "\n",
    "  x = obs$OBSERVATION\n",
    "  y = pred$PREDICTION\n",
    "  \n",
    "  agg <- aggregate(OBSERVATION ~ CELL_LINE, obs, median)\n",
    "  z0 <- agg$OBSERVATION[match(obs$CELL_LINE, agg$CELL_LINE)]\n",
    "  \n",
    "  agg <- aggregate(OBSERVATION ~ COMBINATION_ID, obs, median)\n",
    "  z1 <- agg$OBSERVATION[match(obs$COMBINATION_ID, agg$COMBINATION_ID)]\n",
    "   \n",
    "  parCor <- function(u,v,w) {\n",
    "    numerator = cor(u,v) - cor(u,w) * cor(w,v)\n",
    "    denumerator = sqrt(1-cor(u,w)^2) * sqrt(1-cor(w,v)^2)\n",
    "    return(numerator/denumerator)\n",
    "  }\n",
    "  \n",
    "  numerator=parCor(x,y,z1) - parCor(x,z0,z1) * parCor(z0,y,z1)\n",
    "  denumerator= sqrt(1-parCor(x,z0,z1)^2) * sqrt(1-parCor(z0,y,z1)^2)\n",
    "  \n",
    "  # partial out the mean of synergy across cell lines and combinationations\n",
    "  return(c(score=numerator/denumerator))\n",
    "}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last modified: Wed Feb 03 14:49:11 2016\n",
      "created: Tue Sep 29 22:53:21 2015\n",
      "\n",
      "cell line id 85\n",
      "drug id 119\n",
      "drug target 90\n",
      "mutations 68\n",
      "poly feature 306\n",
      "총 feature 개수:  668\n",
      "train data: ch1_train_combination_and_monoTherapy_qa1_shuffle.csv\n"
     ]
    }
   ],
   "source": [
    "file='challone.ipynb'\n",
    "print \"last modified: %s\" % time.ctime(os.path.getmtime(file)) #파일 수정된 날짜\n",
    "print \"created: %s\\n\" % time.ctime(os.path.getctime(file)) #파일 생성된 날짜\n",
    "\n",
    "cell_line_bool=1\n",
    "drug_id_bool=1\n",
    "drug_target_bool=1\n",
    "mutation_bool=1\n",
    "lasso_polynomial_feature_bool=1\n",
    "lasso_polynomial_feature_leaderboard_bool=0\n",
    "\n",
    "#feature 무엇을 썼는지 file 이름에 명시\n",
    "output_file_name=''\n",
    "if cell_line_bool: output_file_name+='cell_line_id'\n",
    "if drug_id_bool: output_file_name+='drug_id_'\n",
    "if drug_target_bool: output_file_name+='drug_target_'\n",
    "if mutation_bool: output_file_name+='mutation_'\n",
    "if lasso_polynomial_feature_bool: output_file_name+='lasso_polynomial_'\n",
    "if lasso_polynomial_feature_leaderboard_bool: output_file_name+='lasso_polynomial_leaderboard_'\n",
    "output_file_name+='challone_result'\n",
    "\n",
    "libfm_id=0 #libfm의 id 값\n",
    "meta_list=[] #libfm option중 meta id list\n",
    "meta_id=0 #meta id 값\n",
    "\n",
    "if cell_line_bool:\n",
    "    cell_line_id_dict={}\n",
    "    #cell_line을 보면 train data에서 한 cell line은 모든 qa가 -1이다 그러나 제외하지 않고 넣자, 결과가 더 좋음\n",
    "    df=pd.read_csv('input/ch1_train_combination_and_monoTherapy.csv')\n",
    "    for i,name in enumerate(set(df['CELL_LINE'])):\n",
    "        cell_line_id_dict[name]=i\n",
    "        meta_list.append(str(meta_id))\n",
    "\n",
    "    print 'cell line id',len(cell_line_id_dict)\n",
    "    libfm_id+=len(cell_line_id_dict)\n",
    "    meta_id+=1\n",
    "\n",
    "if drug_id_bool:\n",
    "    drug_name_id_dict={}\n",
    "    df=pd.read_csv('drug/Drug_info_release.csv')\n",
    "    for i,name in enumerate(set(df['ChallengeName']),start=libfm_id):\n",
    "        drug_name_id_dict[name]=i\n",
    "        meta_list.append(str(meta_id))\n",
    "    \n",
    "    print 'drug id',len(drug_name_id_dict)\n",
    "    libfm_id+=len(drug_name_id_dict)\n",
    "    meta_id+=1\n",
    "\n",
    "if drug_target_bool:\n",
    "    df=pd.read_csv('drug/Drug_info_release_extended.csv')\n",
    "    drug_target_set=set() # drug target set\n",
    "    for targets in df['Target']:\n",
    "        if pd.notnull(targets):\n",
    "            targetSplit=targets.split(',')\n",
    "            for i in range(len(targetSplit)):\n",
    "                if '*' not in targetSplit[i]: #*이 들어가는 gene target은 해석이 불가능 하므로 제외\n",
    "                    drug_target_set.add(targetSplit[i].strip())\n",
    "\n",
    "    drug_target_id_dict={}\n",
    "    for i,drug_target in enumerate(drug_target_set,start=libfm_id):\n",
    "        drug_target_id_dict [drug_target]=i\n",
    "        meta_list.append(str(meta_id))\n",
    "\n",
    "    drug_target_dict={}\n",
    "    for row in df.itertuples():\n",
    "        tmp=set()\n",
    "        if pd.notnull(row[2]):\n",
    "            targetSplit=row[2].split(',')\n",
    "            for i in range(len(targetSplit)):\n",
    "                if '*' not in targetSplit[i]:\n",
    "                    tmp.add(drug_target_id_dict[targetSplit[i].strip()])\n",
    "        drug_target_dict[row[1]]=tmp\n",
    "\n",
    "    print 'drug target',len(drug_target_set)\n",
    "    libfm_id+=len(drug_target_set)\n",
    "    meta_id+=1\n",
    "\n",
    "\n",
    "if mutation_bool:\n",
    "    df=pd.read_csv('drug/notInMut.csv')\n",
    "    drug_target_set=set() # drug target set\n",
    "    for targets in df['Target']:\n",
    "        if pd.notnull(targets): #빈 공간 아닌 경우\n",
    "            targetSplit=targets.split(',')\n",
    "            for i in range(len(targetSplit)):\n",
    "                if '*' not in targetSplit[i]:\n",
    "                    drug_target_set.add(targetSplit[i].strip())\n",
    "\n",
    "    drug_target_id_dict={}\n",
    "    for i,drug_target in enumerate(drug_target_set,start=libfm_id):\n",
    "        drug_target_id_dict [drug_target]=i\n",
    "        meta_list.append(str(meta_id))\n",
    "\n",
    "    cell_line_mutation={}\n",
    "    df=pd.read_csv('mutation/mutations.csv')\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------\n",
    "    #metastasis는 tumor gene이 drug target에 포함 되어도 mutation feature로 포함하지 않았다\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    for row in df[df['Tumour.origin']=='primary'].itertuples():\n",
    "        gene_name=row[1]\n",
    "        if gene_name in drug_target_id_dict:\n",
    "            if gene_name=='BRAF' and row[15]=='p.V600E':\n",
    "                if row[5] in cell_line_mutation: cell_line_mutation[row[5]].add(drug_target_id_dict['BRAF_V600E'])\n",
    "                else: cell_line_mutation[row[5]]=set([drug_target_id_dict['BRAF_V600E']])\n",
    "            else:\n",
    "                if row[5] in cell_line_mutation: \n",
    "                    cell_line_mutation[row[5]].add(drug_target_id_dict[gene_name])\n",
    "                else: cell_line_mutation[row[5]]=set([drug_target_id_dict[gene_name]])\n",
    "\n",
    "    #drug target gene이 cell line mutation에 없는 경우 -1로 줌\n",
    "    #drug target dimension을 생각할 때 만일 2번 gene target만 존재 할 경우 -1 -1 1 -1 -1 ... 이런 value들을 갖게되는 것이다\n",
    "    drug_target_not_in_cell_line=defaultdict(set)\n",
    "    for cell_line_var in cell_line_mutation:\n",
    "        for drug_target_id_var in drug_target_id_dict.values():\n",
    "            if drug_target_id_var not in cell_line_mutation[cell_line_var]:\n",
    "                drug_target_not_in_cell_line[cell_line_var].add(drug_target_id_var)\n",
    "\n",
    "    print 'mutations',len(drug_target_id_dict)\n",
    "    libfm_id+=len(drug_target_id_dict)\n",
    "    meta_id+=1\n",
    "    \n",
    "if lasso_polynomial_feature_bool:\n",
    "    lasso_poly_feature_list=[]\n",
    "    feature_num=0 #feature 개수\n",
    "    \n",
    "    with open('lasso/df_simple_0.03_350.csv','r') as fr:\n",
    "        lines=fr.readlines()\n",
    "        feature_num=len(lines[0].strip().split(',')[1:])\n",
    "        \n",
    "        for line in lines[1:]:\n",
    "            feature=line.strip().split(',')\n",
    "            result=''\n",
    "            for i in range(len(feature[1:])):\n",
    "                if float(feature[i+1]): result+=str(i+libfm_id)+':'+feature[i+1]+' '\n",
    "            lasso_poly_feature_list.append(result.strip())\n",
    "            \n",
    "    meta_list.extend([str(meta_id)]*feature_num)\n",
    "    print 'poly feature',feature_num\n",
    "    libfm_id+=feature_num\n",
    "    meta_id+=1\n",
    "    \n",
    "if lasso_polynomial_feature_leaderboard_bool:\n",
    "    lasso_poly_feature_leaderboard_list=[]\n",
    "    feature_num=0 #feature 개수\n",
    "    \n",
    "    with open('lasso/df_simple_0.03_350.csv','r') as fr:\n",
    "        lines=fr.readlines()\n",
    "        feature_num=len(lines[0].strip().split(',')[1:])\n",
    "        \n",
    "        for line in lines[1:]:\n",
    "            feature=line.strip().split(',')\n",
    "            result=''\n",
    "            for i in range(len(feature[1:])):\n",
    "                if float(feature[i+1]): result+=str(i+libfm_id)+':'+feature[i+1]+' '\n",
    "            lasso_poly_feature_leaderboard_list.append(result.strip())\n",
    "            \n",
    "    meta_list.extend([str(meta_id)]*feature_num)\n",
    "    print 'poly feature leaderboard',feature_num\n",
    "    libfm_id+=feature_num\n",
    "    meta_id+=1\n",
    "\n",
    "print '총 feature 개수: ',libfm_id\n",
    "\n",
    "trainDir='input/chall1/ch1_train_combination_and_monoTherapy_qa1_shuffle.csv'\n",
    "print 'train data:',trainDir.split('/')[-1]\n",
    "\n",
    "#최종제출\n",
    "#testDir='input/chall1/ch1_leaderBoard_monoTherapy_blankErased.csv'\n",
    "#print testDir.split('/')[-1]\n",
    "\n",
    "libfm_train='libfmInput/fmTrain.libfm' #libfm input file 이름\n",
    "libfm_test='libfmInput/fmTest.libfm'\n",
    "meta_file_directory='libfmInput/meta.txt' #group data file 이름\n",
    "\n",
    "with open(meta_file_directory,'w') as fw:\n",
    "    result=''\n",
    "    for item in meta_list:\n",
    "        result+=item+'\\n'\n",
    "    fw.write(result)\n",
    "\n",
    "def makeLibfmInput(file_directory,libfm_file,score):\n",
    "    df=pd.read_csv(file_directory)\n",
    "\n",
    "    with open(libfm_file,'w') as fw:\n",
    "        featureString=''\n",
    "        row_id=0\n",
    "        for row in df.itertuples():\n",
    "            synergy_score=row[12]\n",
    "            cell_line_name=row[1]\n",
    "            drug_a=row[2]\n",
    "            drug_b=row[3]\n",
    "            \n",
    "            if score: featureString+=str(synergy_score)+' ' # score\n",
    "            else: featureString+='0 ' # score\n",
    "\n",
    "            if cell_line_bool:\n",
    "                if cell_line_name in cell_line_id_dict: featureString+=str(cell_line_id_dict[cell_line_name])+':1 ' # cell line\n",
    "\n",
    "            if mutation_bool:\n",
    "                if cell_line_name in cell_line_mutation:\n",
    "                    for x in cell_line_mutation[cell_line_name]: featureString+=str(x)+':1 '\n",
    "                if cell_line_name in drug_target_not_in_cell_line:\n",
    "                    for x in drug_target_not_in_cell_line[cell_line_name]: featureString+=str(x)+':-1 '\n",
    "\n",
    "            if drug_id_bool: featureString+=str(drug_name_id_dict[drug_a])+':1 '+str(drug_name_id_dict[drug_b])+':1 '\n",
    "\n",
    "            if drug_target_bool:\n",
    "                u=drug_target_dict[drug_a].intersection(drug_target_dict[drug_b])\n",
    "                for x in u: featureString+=str(x)+':2 ' #target이 겹치는 경우 feature의 value를 2배로 주었다\n",
    "                for x in drug_target_dict[drug_a]-u: featureString+=str(x)+':1 '\n",
    "                for x in drug_target_dict[drug_b]-u: featureString+=str(x)+':1 '\n",
    "            \n",
    "            if lasso_polynomial_feature_bool:\n",
    "                featureString+=lasso_poly_feature_list[row_id]+' '\n",
    "                \n",
    "            if lasso_polynomial_feature_leaderboard_bool:\n",
    "                featureString+=lasso_polynomial_feature_leaderboard_bool[row_id]+' '\n",
    "            \n",
    "            featureString=featureString.strip()+'\\n'\n",
    "            row_id+=1 #lasso feature를 위한 index\n",
    "            \n",
    "        fw.write(featureString)\n",
    "\n",
    "makeLibfmInput(trainDir,libfm_train,True)\n",
    "#makeLibfmInput(testDir,libfm_test,False) #최종 제출시\n",
    "        \n",
    "#train data를 cross validation set으로 분할하는 코드 (미리 train data가 shuffle 되어 있어야 한다)\n",
    "#input: libfm_train\n",
    "#output: cvTrain.libfm & cvTest.libfm\n",
    "\n",
    "is_cross_validation=False\n",
    "if is_cross_validation:\n",
    "    feature_string=[] #feature string\n",
    "    number_of_rows=0 #number of rows\n",
    "\n",
    "    print 'cross validation libfm data:',libfm_train.split('/')[-1]\n",
    "    with open(libfm_train,'r') as fr:\n",
    "        for row in fr:\n",
    "            feature_string.append(row.strip())\n",
    "            number_of_rows+=1\n",
    "\n",
    "    subset_size=number_of_rows/10\n",
    "    for i in range(10):\n",
    "        with open('cv/cv_test'+str(i)+'.libfm','w') as fw:\n",
    "            if i==9:\n",
    "                for item in feature_string[i*subset_size:]:\n",
    "                    print>>fw, item\n",
    "            else:\n",
    "                for item in feature_string[i*subset_size:][:subset_size]:\n",
    "                    print>>fw, item\n",
    "        with open('cv/cv_train'+str(i)+'.libfm','w') as fw:\n",
    "            for item in feature_string[:i*subset_size] + feature_string[(i+1)*subset_size:]:\n",
    "                print>> fw, item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#challenege 1 cross validation sgd \\r-> escape 문\n",
    "#libFM 동시에 돌리는 코드 ( 10 cross validation은 시간이 오래 걸린다)\n",
    "#\n",
    "#input: cvTrain'X'.libfm, cvTest'X'.libfm, meta'X'.txt\n",
    "#output: prediction/result0~9\n",
    "\n",
    "def create_cross_validation_libFM_bat_file(dim='30',iter='1000',regular='0,0,1',method='mcmc'):\n",
    "    for i in range(10):\n",
    "        with open('bat/train'+str(i)+'.bat','w') as fw:\n",
    "            fw.write(\"..\\\\libfm -task r -train ..\\\\cv\\\\cv_train\"+str(i)+\".libfm -test ..\\\\cv\\\\cv_test\"+str(i)+\".libfm -dim '1,1,\")\n",
    "            if method=='sgd':\n",
    "                fw.write(dim+\"' -iter \"+iter+\" -method sgd -learn_rate 0.00001 -regular \"+regular)\n",
    "            elif method=='mcmc':\n",
    "                fw.write(dim+\"' -iter \"+iter)\n",
    "            fw.write(\" -meta ..\\\\libfmInput\\\\meta\"+str(i)+\".txt -init_stdev 0.1 -out ..\\\\prediction\\\\result\"+str(i))\n",
    "            \n",
    "create_cross_validation_libFM_bat_file(iter='1000',regular='0,0.01,1',method='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch1_train_combination_and_monoTherapy_qa1_shuffle.csv cv/1-1cv.csv\n",
      "0.250985291443\n",
      "0.22,0.36\n"
     ]
    }
   ],
   "source": [
    "#cross validation 결과 출력 코드\n",
    "#\n",
    "#input: result0 ~ result9\n",
    "#output: cvFileName\n",
    "\n",
    "cvFileName='cv/cross_validation'+output_file_name+'.csv'\n",
    "\n",
    "prTest=pd.read_csv(trainDir)\n",
    "pred=prTest.loc[:,['CELL_LINE','COMBINATION_ID','SYNERGY_SCORE']]\n",
    "\n",
    "fold=10\n",
    "tmp=[]\n",
    "for j in range(fold):\n",
    "    with open('prediction/result'+str(j),'r') as fr:\n",
    "        for r in fr:tmp.append(float(r.strip()))\n",
    "\n",
    "pred.loc[:,'PREDICTION']=np.asarray(tmp)\n",
    "pred.to_csv(cvFileName,index=False)\n",
    "\n",
    "quiet=False #score 결과 출력\n",
    "if not quiet:\n",
    "    print trainDir.split('/')[-1],cvFileName\n",
    "    #global score\n",
    "    print robjects.r['getGlobalScore_ch1'](trainDir,cvFileName)[0]\n",
    "    confidenceFile='NA'\n",
    "    print str(robjects.r['getDrugCombiScore_ch1'](trainDir,cvFileName,confidenceFile)[0])+','+str(robjects.r['getDrugCombiScore_ch1'](trainDir,cvFileName,confidenceFile)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  leaderboard libFM submission code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#leader board bat file\n",
    "def create_leaderboard_libFM_bat_file(dim='30',iter='1000',regular='0,0,1',method='mcmc'):\n",
    "    with open('bat/train_leaderboard.bat','w') as fw:\n",
    "        fw.write(\"..\\\\libfm -task r -train ..\\\\libfmInput\\\\fmTrain.libfm -test ..\\\\libfmInput\\\\fmTest.libfm -dim '1,1,\")\n",
    "        if method=='sgd':\n",
    "            fw.write(dim+\"' -iter \"+iter+\" -method sgd -learn_rate 0.00001 -regular \"+regular)\n",
    "        elif method=='mcmc':\n",
    "            fw.write(dim+\"' -iter \"+iter)\n",
    "        fw.write(\"-meta ..\\\\libfmInput\\\\meta.txt -init_stdev 0.1 -out ..\\\\prediction\\\\result_leaderboard\")\n",
    "\n",
    "create_leaderboard_libFM_bat_file(iter='1000',regular='0,0.01,1',method='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leaderboardFileName='chall1/1-2submission2.csv'\n",
    "prTest=pd.read_csv(testDir)\n",
    "pred=prTest.loc[:,['CELL_LINE','COMBINATION_ID']]\n",
    "\n",
    "fold=10\n",
    "tmp=[]\n",
    "with open('prediction/result_leaderboard','r') as fr:\n",
    "    for r in fr:tmp.append(float(r.strip()))\n",
    "\n",
    "pred.loc[:,'PREDICTION']=np.asarray(tmp)\n",
    "pred.to_csv(leaderboardFileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if prerher2Bool:\n",
    "    pr=pd.read_csv('cell/cbioportal_EMT_BREAST.csv')\n",
    "    clprerher2={}\n",
    "    #for row in pr[['CELL_LINE','HER2']].itertuples():\n",
    "    #    tmp=''\n",
    "    #    if row[2]:tmp+=str(libfmId)+':'+str(row[2])+' '\n",
    "    #    #if row[3]:tmp+=str(libfmId+1)+':'+str(row[3])+' '\n",
    "    #    #if row[4]:tmp+=str(libfmId+2)+':'+str(row[4])+' '\n",
    "    #    clprerher2[row[1]]=tmp\n",
    "    #libfmId+=1\n",
    "    #groupData.extend(str(groupId))\n",
    "    \n",
    "    for row in pr[['CELL_LINE','PR','ER','HER2']].itertuples():\n",
    "        tmp=''\n",
    "        if row[2]:tmp+=str(libfmId)+':'+str(row[2])+' '\n",
    "        if row[3]:tmp+=str(libfmId+1)+':'+str(row[3])+' '\n",
    "        if row[4]:tmp+=str(libfmId+2)+':'+str(row[4])+' '\n",
    "        clprerher2[row[1]]=tmp\n",
    "    libfmId+=3\n",
    "    groupData.extend([str(groupId)]*3)\n",
    "    groupId+=1\n",
    "    print 'PR,ER,HER2',3\n",
    "    \n",
    "if monoconcenBool:\n",
    "    monoconcen={}\n",
    "    denominator=100 #교수님의 전언 100으로 나누어라!\n",
    "    print 'normalized by',denominator,\n",
    "    for csvfile in os.listdir('ch1_training_combinations/'):\n",
    "        pr=pd.read_csv('ch1_training_combinations/'+csvfile,index_col=0,engine='c')\n",
    "        monoconcenVal=[]\n",
    "        monoconcenVal.extend(pr.loc[:,'0'][1:6]) #Agent 1, Agent 2=0\n",
    "        monoconcenVal.extend(pr.loc['0',:][1:6]) #Agent 2, Agent 1=0\n",
    "        monoconcenVal=[float(x)/denominator for x in monoconcenVal]\n",
    "\n",
    "        cellDrugcomboName=csvfile[:-9]\n",
    "        if cellDrugcomboName in monoconcen:monoconcen[cellDrugcomboName].append(monoconcenVal)\n",
    "        else:monoconcen[cellDrugcomboName]=[monoconcenVal]\n",
    "\n",
    "    monoconcenAverage={}\n",
    "    for mc in monoconcen:\n",
    "        if len(monoconcen[mc])==3:averagetmp=[sum(x)/3 for x in zip(monoconcen[mc][0],monoconcen[mc][1],monoconcen[mc][2])]\n",
    "        elif len(monoconcen[mc])==2:averagetmp=[sum(x)/2 for x in zip(monoconcen[mc][0],monoconcen[mc][1])]\n",
    "        else:averagetmp=monoconcen[mc][0]\n",
    "\n",
    "        tmp=''\n",
    "        for i in range(len(averagetmp)):\n",
    "            tmp+=str(libfmId+i)+':'+str(averagetmp[i])+' '\n",
    "        monoconcenAverage[mc]=tmp\n",
    "       \n",
    "    groupData.extend([str(groupId)]*10)\n",
    "    libfmId+=10\n",
    "    groupId+=1\n",
    "    print 'monotherapy concentration',10\n",
    "\n",
    "if gseaBool:\n",
    "    gseaFileName = \"gsea/gsea_thre2_noMetabolism.csv\"\n",
    "    pr=pd.read_csv(gseaFileName,index_col=0)\n",
    "    pathwayTmp=pr.columns\n",
    "    pathwayId={}\n",
    "    for i,name in enumerate(pathwayTmp,start=libfmId):\n",
    "        pathwayId[name]=i\n",
    "        groupData.append(str(groupId))\n",
    "        \n",
    "    clPathway=defaultdict(list)\n",
    "    for col in pr.columns:\n",
    "        for cellLine in pr.index:\n",
    "            if pr.loc[cellLine,col]:clPathway[cellLine].append(pathwayId[col])\n",
    "    \n",
    "    libfmId+=len(pathwayId)\n",
    "    groupId+=1\n",
    "    print 'GSEA',len(pathwayId)\n",
    "    \n",
    "if tspairBool:\n",
    "    pr=pd.read_csv(\"TSpair/tspair_10_negbinary(0.7).csv\",index_col=0)\n",
    "    tspairTmp=pr.columns\n",
    "    tspairId={}\n",
    "    for i,name in enumerate(tspairTmp,start=libfmId):\n",
    "        tspairId[name]=i\n",
    "        groupData.append(str(groupId))\n",
    "\n",
    "    libfmId+=len(tspairId)\n",
    "\n",
    "    clTSpair=defaultdict(list) \n",
    "    for col in pr.columns:\n",
    "        for cellLine in pr.index:\n",
    "            diff = pr[col].max() - pr[col].min()\n",
    "            #if pr.loc[cellLine,col]:clTSpair[cellLine].append(str(tspairId[col])+\":\"+str(pr.loc[cellLine,col]/diff))   \n",
    "            if pr.loc[cellLine,col]:clTSpair[cellLine].append(str(tspairId[col])+\":\"+str(pr.loc[cellLine,col]))  \n",
    "\n",
    "    groupId+=1\n",
    "    print 'TSpair 개수:',len(tspairId)\n",
    "if drug_target_bool1:\n",
    "    pr=pd.read_csv('drug/Drug_info_release_extended.csv')\n",
    "    dtl=set() # drug target list\n",
    "    for targets in pr['Target']:\n",
    "        if pd.notnull(targets):\n",
    "            targetSplit=targets.split(',')\n",
    "            for i in range(len(targetSplit)):\n",
    "                if '*' not in targetSplit[i]:\n",
    "                    dtl.add(targetSplit[i].strip())\n",
    "\n",
    "    dtId={}\n",
    "    for i,d0 in enumerate(dtl,start=libfmId):\n",
    "        dtId[d0]=i\n",
    "        groupData.append(str(groupId))\n",
    "\n",
    "    ddt1={}\n",
    "    for row in pr.itertuples():\n",
    "        tmp=set()\n",
    "        if pd.notnull(row[2]):\n",
    "            targetSplit=row[2].split(',')\n",
    "            for i in range(len(targetSplit)):\n",
    "                if '*' not in targetSplit[i]:\n",
    "                    tmp.add(dtId[targetSplit[i].strip()])\n",
    "        ddt1[row[1]]=tmp\n",
    "\n",
    "    print 'drug target1',len(dtl)\n",
    "    libfmId+=len(dtl)\n",
    "    groupId+=1    \n",
    "    \n",
    "if maxconcBool:\n",
    "    maxconca=libfmId\n",
    "    maxconcb=libfmId+1\n",
    "    libfmId+=2\n",
    "    groupData.extend([str(groupId),str(groupId)])\n",
    "    groupId+=1\n",
    "    print 'max concentration',2\n",
    "\n",
    "if einfBool:\n",
    "    einfaId=libfmId\n",
    "    einfbId=libfmId+1\n",
    "    libfmId+=2\n",
    "    groupData.extend([str(groupId),str(groupId)])\n",
    "    groupId+=1\n",
    "    print 'einf',2\n",
    "if drugCombBool==1:\n",
    "    dc={}\n",
    "    pr=pd.read_csv('input/ch1_train_combination_and_monoTherapy.csv')\n",
    "    for i,name in enumerate(set(pr['COMBINATION_ID']),start=libfmId):\n",
    "        dc[name]=i\n",
    "        groupData.append(str(groupId))\n",
    "    libfmId+=len(dc)\n",
    "    groupId+=1\n",
    "    print 'drug combination id',len(dc)\n",
    "if lassoPolyBool:\n",
    "    df=pd.read_csv('tmp/lasso_polyfeatures.csv',index_col=0)\n",
    "    idPolyFeature={}\n",
    "    for _ in df.index:\n",
    "        feature=''\n",
    "        for poly in df.columns:\n",
    "            if df.loc[_,poly]:feature+=str(int(poly)+libfmId)+':'+str(df.loc[_,poly])+' '\n",
    "        idPolyFeature[_]=feature\n",
    "    \n",
    "    featureNum=len(df.columns)\n",
    "    groupData.extend([str(groupId)]*featureNum)\n",
    "    libfmId+=featureNum\n",
    "    groupId+=1\n",
    "    print 'lasso',featureNum\n",
    "if stageBool:\n",
    "    pr=pd.read_csv('cell/cell_comment_stage.csv')\n",
    "    clStage={}\n",
    "    maxStage=max(pr['stage'])\n",
    "    #print maxStage\n",
    "    for row in pr.itertuples():\n",
    "        #row[1] == cell line name, row[2] == stage\n",
    "        clStage[row[1]]=str(libfmId+row[2]-1)+':1'\n",
    "\n",
    "    libfmId+=maxStage\n",
    "    groupData.extend([str(groupId)]*maxStage)\n",
    "    groupId+=1\n",
    "    print 'cell comment stage',maxStage\n",
    "    \n",
    "if lipinskiBool:\n",
    "    pr=pd.read_csv('drug/drug_lipinski.csv')\n",
    "    drugLipinski={}\n",
    "    maxLipinski=int(max(pr.loc[pr.Lipinski.notnull(),'Lipinski']))\n",
    "    \n",
    "    for row in pr[pr.Lipinski.notnull()].itertuples():\n",
    "        drugLipinski[row[1]]=str(libfmId+int(row[2]))+':1'\n",
    "\n",
    "    libfmId+=maxLipinski\n",
    "    groupData.extend([str(groupId)]*maxLipinski)\n",
    "    groupId+=1\n",
    "    print 'lipinski',maxLipinski\n",
    "    \n",
    "if gexBool:\n",
    "    dtl=[]\n",
    "    with open('gex/drugTargetGex.txt','r') as fr:\n",
    "        for line in fr:\n",
    "            dtl.append(line.strip())\n",
    "\n",
    "    gexId={}\n",
    "    for i,d in enumerate(dtl,start=libfmId):\n",
    "        gexId[d]=i\n",
    "        groupData.append(str(groupId))    \n",
    "\n",
    "    libfmId+=len(gexId)\n",
    "    groupId+=1\n",
    "\n",
    "    df=pd.read_csv('gex/gex.csv',index_col=0)\n",
    "    df=df.loc[dtl,:]\n",
    "    clGex={}\n",
    "    for gene in df.index:\n",
    "        std=df.loc[gene,:].std()\n",
    "        mean=df.loc[gene,:].mean()\n",
    "        for cellLine in df.columns:\n",
    "            if cellLine not in clGex: clGex[cellLine]=''\n",
    "            stdCoef=0 #이걸 바꿔주면서 실험해보면 어떨까, 0이면 그냥 양 음 체크\n",
    "            #양의 값\n",
    "            if df.loc[gene,cellLine]>=(mean+stdCoef*std):clGex[cellLine]+=str(gexId[gene])+':'+str(df.loc[gene,cellLine]/14)+' '\n",
    "            #음의 값\n",
    "            #if df.loc[gene,cellLine]<=(mean-stdCoef*std):clGex[cellLine]+=str(gexId[gene])+':'+str(df.loc[gene,cellLine]/14)+' '\n",
    "    \n",
    "    print 'gex',len(gexId)\n",
    "\n",
    "if stageBool:\n",
    "    if row[1] in clStage: featureString+=clStage[row[1]]+' '\n",
    "if lipinskiBool:\n",
    "    if row[2] in drugLipinski: featureString+=drugLipinski[row[2]]+' '\n",
    "    if row[3] in drugLipinski: featureString+=drugLipinski[row[3]]+' '\n",
    "\n",
    "if gexBool:\n",
    "    if row[1] in clGex: featureString+=clGex[row[1]]\n",
    "    \n",
    "if lassoPolyBool:\n",
    "    featureString+=idPolyFeature[rowId]\n",
    "    rowId+=1\n",
    "if drug_target_bool1:\n",
    "    u=ddt1[row[2]].intersection(ddt1[row[3]])\n",
    "    for x in u: featureString+=str(x)+':2 ' #target이 겹치는 경우 feature의 value를 2배로 주었다\n",
    "    for x in ddt1[row[2]]-u: featureString+=str(x)+':1 '\n",
    "    for x in ddt1[row[3]]-u: featureString+=str(x)+':1 '\n",
    "\n",
    "if maxconcBool:\n",
    "    featureString+=str(maxconca)+':'+str(row[4]/pr['MAX_CONC_A'].max())+' '\n",
    "    featureString+=str(maxconcb)+':'+str(row[5]/pr['MAX_CONC_B'].max())+' '\n",
    "\n",
    "if einfBool:\n",
    "    featureString+=str(einfaId)+':'+str(row[8]/100)+' '\n",
    "    featureString+=str(einfbId)+':'+str(row[11]/100)+' '\n",
    "\n",
    "if prerher2Bool:\n",
    "    if row[1] in clprerher2:featureString+=clprerher2[row[1]]\n",
    "\n",
    "if monoconcenBool:\n",
    "    if row[14]+'.'+row[1] in monoconcenAverage:featureString+=monoconcenAverage[row[14]+'.'+row[1]]\n",
    "\n",
    "if gseaBool:\n",
    "    if row[1] in clPathway:\n",
    "        for x in clPathway[row[1]]:featureString+=str(x)+':1 '\n",
    "\n",
    "if tspairBool:\n",
    "    if row[1] in clTSpair: featureString+=' '.join(clTSpair[row[1]])+' '"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
